{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa6f7587",
   "metadata": {},
   "source": [
    "# Cleaning Datasets for Gentrification Analysis\n",
    "\n",
    "Each dataset below is from the City of New York's open data. I will be using each of these to contribute to an analysis of how different areas of NYC have changed over the last ~10 years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae11d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statments\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2322defa",
   "metadata": {},
   "source": [
    "#### PLUTO (Primary Tax-Use Land Output) Dataset\n",
    "\n",
    "This dataset contains important information for each building, including: location, building classification codes (what each building is used for), property assesment values, zoning information, and more. My other datasets contain information like evictions, sale prices, building permits, buyers/sellers; PLUTO contains information about the type of buildings in which those events happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5453b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original PLUTO shape: (857736, 101)\n",
      "\n",
      "Cleaned PLUTO shape: (857736, 31)\n",
      "Residential properties: 716,254\n",
      "BBL sample: ['4064210038', '4051750020', '4051730111', '4051740016', '4064130046']\n",
      "\n",
      "✓ PLUTO cleaned and saved\n"
     ]
    }
   ],
   "source": [
    "# Cleaning PLUTO\n",
    "\n",
    "# Load PLUTO\n",
    "pluto = pd.read_csv('Primary_Land_Use_Tax_Lot_Output_(PLUTO)_20251112.csv', low_memory=False)\n",
    "\n",
    "print(f\"Original PLUTO shape: {pluto.shape}\")\n",
    "\n",
    "# Keep columns relevant for gentrification analysis\n",
    "columns_to_keep = [\n",
    "    'BBL',                  # Borough-Block-Lot ID (unique property identifier)\n",
    "    'borough',              # Borough code (MN, BX, BK, QN, SI)\n",
    "    'Tax block',            # Tax block number\n",
    "    'Tax lot',              # Tax lot number\n",
    "    'address',              # Street address\n",
    "    'postcode',             # ZIP code\n",
    "    'community board',      # Community board district\n",
    "    'census tract 2010',    # Census tract (for demographic data)\n",
    "    'bldgclass',            # Building classification code (A=single family, B=2-family, C/D=apartments)\n",
    "    'landuse',              # Land use category code\n",
    "    'ownertype',            # Owner type (P=Private, C=City, M=Mixed, O=Other)\n",
    "    'ownername',            # Property owner name (helps identify institutional owners)\n",
    "    'numbldgs',             # Number of buildings on the lot\n",
    "    'numfloors',            # Number of floors in building\n",
    "    'unitsres',             # Number of residential units (KEY for gentrification)\n",
    "    'unitstotal',           # Total number of units (residential + commercial)\n",
    "    'lotarea',              # Lot area in square feet\n",
    "    'bldgarea',             # Total building area in square feet\n",
    "    'resarea',              # Residential area in square feet\n",
    "    'comarea',              # Commercial area in square feet\n",
    "    'yearbuilt',            # Year building was built\n",
    "    'yearalter1',           # Year of first major alteration\n",
    "    'yearalter2',           # Year of second major alteration\n",
    "    'histdist',             # Historic district name (if applicable)\n",
    "    'landmark',             # Landmark designation (if applicable)\n",
    "    'assessland',           # Assessed land value\n",
    "    'assesstot',            # Total assessed value (land + building)\n",
    "    'exempttot',            # Total tax exemptions\n",
    "    'latitude',             # Latitude coordinate\n",
    "    'longitude'             # Longitude coordinate\n",
    "]\n",
    "\n",
    "# Select only the columns we want\n",
    "pluto_clean = pluto[columns_to_keep].copy()\n",
    "\n",
    "# Mark residential properties (building classes A, B, C, D)\n",
    "pluto_clean['is_residential'] = pluto_clean['bldgclass'].astype(str).str[0].isin(['A', 'B', 'C', 'D'])\n",
    "\n",
    "# Remove invalid BBLs\n",
    "pluto_clean = pluto_clean[pluto_clean['BBL'].notna()]\n",
    "pluto_clean['BBL'] = pluto_clean['BBL'].astype(str).str.replace('.0', '', regex=False)\n",
    "pluto_clean = pluto_clean[pluto_clean['BBL'].str.len() == 10]\n",
    "\n",
    "# Convert numeric columns\n",
    "numeric_cols = ['numfloors', 'unitsres', 'unitstotal', 'lotarea', 'bldgarea', \n",
    "                'resarea', 'comarea', 'assessland', 'assesstot', 'exempttot', 'yearbuilt']\n",
    "for col in numeric_cols:\n",
    "    pluto_clean[col] = pd.to_numeric(pluto_clean[col], errors='coerce')\n",
    "\n",
    "print(f\"\\nCleaned PLUTO shape: {pluto_clean.shape}\")\n",
    "print(f\"Residential properties: {pluto_clean['is_residential'].sum():,}\")\n",
    "\n",
    "# BBL example meaning: 1001230045 = Manhattan (1), Block 00123, Lot 0045\n",
    "print(f\"BBL sample: {pluto_clean['BBL'].head().tolist()}\") \n",
    "\n",
    "# Save\n",
    "pluto_clean.to_csv('pluto_cleaned.csv', index=False)\n",
    "print(\"\\n✓ PLUTO cleaned and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08633c98",
   "metadata": {},
   "source": [
    "#### Evictions Dataset\n",
    "\n",
    "This dataset's purpose is pretty self-explanatory. Places with increasing rent and new groups of people moving in means that currrent residents will be displaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea4ae2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original evictions shape: (118771, 20)\n",
      "\n",
      "After filtering to executed evictions: (118771, 14)\n",
      "After filtering to residential only: (108122, 14)\n",
      "\n",
      "Final cleaned evictions: (100917, 17)\n",
      "\n",
      "=== Evictions by Year ===\n",
      "eviction_year\n",
      "2017    19219\n",
      "2018    18455\n",
      "2019    15836\n",
      "2020     2853\n",
      "2021      147\n",
      "2022     3821\n",
      "2023    11438\n",
      "2024    14657\n",
      "2025    14491\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Evictions by Borough ===\n",
      "BOROUGH\n",
      "BRONX            34499\n",
      "BROOKLYN         28157\n",
      "QUEENS           19216\n",
      "MANHATTAN        15653\n",
      "STATEN ISLAND     3392\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Date Range ===\n",
      "Earliest: 2017-01-03 00:00:00\n",
      "Latest: 2025-11-10 00:00:00\n",
      "\n",
      "=== Buildings with Multiple Evictions ===\n",
      "Buildings with 5+ evictions: 4447\n",
      "Buildings with 10+ evictions: 1302\n",
      "\n",
      "✓ Evictions cleaned and saved!\n",
      "✓ Eviction counts per building saved to evictions_per_bbl.csv\n"
     ]
    }
   ],
   "source": [
    "# Cleaning Evictions\n",
    "\n",
    "# Load evictions\n",
    "evictions = pd.read_csv('Evictions_20251112.csv', low_memory=False)\n",
    "\n",
    "print(f\"Original evictions shape: {evictions.shape}\")\n",
    "\n",
    "# Keep relevant columns\n",
    "columns_to_keep = [\n",
    "    'Court Index Number',           # Unique identifier for the case\n",
    "    'Docket Number ',               # Another case identifier (note the space!)\n",
    "    'Eviction Address',             # Street address\n",
    "    'Eviction Apartment Number',    # Apartment number (for counting evictions per building)\n",
    "    'Executed Date',                # When eviction actually happened (KEY)\n",
    "    'Residential/Commercial',       # Property type\n",
    "    'BOROUGH',                      # Borough\n",
    "    'Eviction Postcode',            # ZIP code\n",
    "    'BBL',                          # Property ID (to link with PLUTO, ACRIS, etc.)\n",
    "    'Latitude',                     # For mapping\n",
    "    'Longitude',                    # For mapping\n",
    "    'Community Board',              # Neighborhood district\n",
    "    'Census Tract',                 # For demographic analysis\n",
    "    'NTA'                           # Neighborhood Tabulation Area\n",
    "]\n",
    "\n",
    "evictions_clean = evictions[columns_to_keep].copy()\n",
    "\n",
    "# Clean column names (remove trailing spaces)\n",
    "evictions_clean.columns = evictions_clean.columns.str.strip()\n",
    "\n",
    "# Convert date to datetime\n",
    "evictions_clean['Executed Date'] = pd.to_datetime(evictions_clean['Executed Date'], errors='coerce')\n",
    "\n",
    "# Filter to only executed evictions (remove rows where Executed Date is missing)\n",
    "evictions_clean = evictions_clean[evictions_clean['Executed Date'].notna()].copy()\n",
    "\n",
    "print(f\"\\nAfter filtering to executed evictions: {evictions_clean.shape}\")\n",
    "\n",
    "# Filter to only RESIDENTIAL evictions (for gentrification focus)\n",
    "evictions_clean['Residential/Commercial'] = evictions_clean['Residential/Commercial'].str.strip().str.upper()\n",
    "evictions_clean = evictions_clean[evictions_clean['Residential/Commercial'] == 'RESIDENTIAL'].copy()\n",
    "\n",
    "print(f\"After filtering to residential only: {evictions_clean.shape}\")\n",
    "\n",
    "# Create time-based columns for analysis\n",
    "evictions_clean['eviction_year'] = evictions_clean['Executed Date'].dt.year\n",
    "evictions_clean['eviction_month'] = evictions_clean['Executed Date'].dt.month\n",
    "evictions_clean['eviction_year_month'] = evictions_clean['Executed Date'].dt.to_period('M').astype(str)\n",
    "\n",
    "# Clean borough names\n",
    "evictions_clean['BOROUGH'] = evictions_clean['BOROUGH'].str.strip().str.upper()\n",
    "\n",
    "# Clean BBL (ensure it's string with no decimals)\n",
    "evictions_clean['BBL'] = evictions_clean['BBL'].astype(str).str.replace('.0', '', regex=False)\n",
    "evictions_clean['BBL'] = evictions_clean['BBL'].str.strip()\n",
    "\n",
    "# Remove rows with missing BBL (can't link to other datasets without it)\n",
    "evictions_clean = evictions_clean[evictions_clean['BBL'].notna()]\n",
    "evictions_clean = evictions_clean[evictions_clean['BBL'] != '']\n",
    "evictions_clean = evictions_clean[evictions_clean['BBL'] != 'nan']\n",
    "\n",
    "# Clean addresses\n",
    "evictions_clean['Eviction Address'] = evictions_clean['Eviction Address'].str.strip().str.upper()\n",
    "\n",
    "print(f\"\\nFinal cleaned evictions: {evictions_clean.shape}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n=== Evictions by Year ===\")\n",
    "print(evictions_clean['eviction_year'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n=== Evictions by Borough ===\")\n",
    "print(evictions_clean['BOROUGH'].value_counts())\n",
    "\n",
    "print(\"\\n=== Date Range ===\")\n",
    "print(f\"Earliest: {evictions_clean['Executed Date'].min()}\")\n",
    "print(f\"Latest: {evictions_clean['Executed Date'].max()}\")\n",
    "\n",
    "# Check for multiple evictions at same address\n",
    "print(\"\\n=== Buildings with Multiple Evictions ===\")\n",
    "evictions_per_bbl = evictions_clean.groupby('BBL').size().reset_index(name='eviction_count')\n",
    "print(f\"Buildings with 5+ evictions: {(evictions_per_bbl['eviction_count'] >= 5).sum()}\")\n",
    "print(f\"Buildings with 10+ evictions: {(evictions_per_bbl['eviction_count'] >= 10).sum()}\")\n",
    "\n",
    "# Save cleaned data\n",
    "evictions_clean.to_csv('evictions_cleaned.csv', index=False)\n",
    "print(\"\\n✓ Evictions cleaned and saved!\")\n",
    "\n",
    "# Optional: Save the eviction counts per building for quick analysis\n",
    "evictions_per_bbl.to_csv('evictions_per_bbl.csv', index=False)\n",
    "print(\"✓ Eviction counts per building saved to evictions_per_bbl.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ff38a",
   "metadata": {},
   "source": [
    "#### ACRIS Datasets\n",
    "\n",
    "##### NOTE: THE CODE FROM HERE DOWN IS IRRELAVANT TO FINAL PRESENTATION, I DID NOT END UP USING THESE DATASETS\n",
    "\n",
    "There are three ACRIS files. Property Master contains transaction details. Property Legals contains property information. Property Parties details buyer/seller details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a3367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ACRIS Master...\n",
      "Loading Document Control Codes...\n",
      "\n",
      "Original Master records: 16,834,719\n",
      "\n",
      "=== Document Types in Master ===\n",
      "DOC. TYPE\n",
      "MTGE        4185390\n",
      "DEED        3602605\n",
      "SAT         2599314\n",
      "ASST        2189753\n",
      "PAT         1045344\n",
      "AGMT         912048\n",
      "RPTT&RET     385121\n",
      "RPTT         211052\n",
      "AL&R         194600\n",
      "REL          169384\n",
      "TL&R         145830\n",
      "SAGE         132797\n",
      "PREL         116896\n",
      "RTXL         108331\n",
      "DEED, TS      90671\n",
      "M&CON         71914\n",
      "SUBM          59625\n",
      "SMIS          57799\n",
      "DTL           56542\n",
      "CERT          53998\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== DEED Document Types (from control codes) ===\n",
      "['ASTU' 'CNTR' 'CODP' 'DCTO' 'DEED' 'EASE' 'IDED' 'LEAS' 'LTPA' 'SUBL'\n",
      " 'VAC' 'CDEC' 'DEEDO' 'DEVR' 'DECM' 'MLEA' 'MCON' 'ACON' 'CORRD' 'CONDEED'\n",
      " 'REIT' 'NAPP' 'DEED COR' 'DEED, LE' 'CORR, LE' 'DEED, TS' 'AIRRIGHT'\n",
      " 'SI CORR' 'DEEDP' 'TORREN' 'DEED, RC' 'SCDEC' 'TODD' 'RTOD']\n",
      "\n",
      "Deed transactions: 3,868,681\n",
      "Deeds from 2015+: 719,339\n",
      "After filtering low amounts: 415,193\n",
      "\n",
      "=== Sales by Year ===\n",
      "sale_year\n",
      "2015    41695\n",
      "2016    40823\n",
      "2017    43479\n",
      "2018    39633\n",
      "2019    37591\n",
      "2020    27487\n",
      "2021    43005\n",
      "2022    41240\n",
      "2023    34893\n",
      "2024    35091\n",
      "2025    30256\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Sales by Borough ===\n",
      "borough_name\n",
      "Manhattan    382803\n",
      "Queens        15301\n",
      "Brooklyn      14376\n",
      "Bronx          2713\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Saved 415,193 deed records to acris_master_cleaned.csv\n",
      "\n",
      "✓ Found 414,018 unique document IDs\n",
      "✓ Saved document IDs to document_ids_for_parties.csv\n"
     ]
    }
   ],
   "source": [
    "# Clean ACRIS Master\n",
    "\n",
    "# Load files\n",
    "print(\"Loading ACRIS Master...\")\n",
    "master = pd.read_csv('ACRIS_-_Real_Property_Master_20251112.csv', low_memory=False)\n",
    "\n",
    "print(\"Loading Document Control Codes...\")\n",
    "doc_codes = pd.read_csv('ACRIS_-_Document_Control_Codes_20251112.csv')\n",
    "\n",
    "print(f\"\\nOriginal Master records: {len(master):,}\")\n",
    "\n",
    "# Check what document types we have\n",
    "print(\"\\n=== Document Types in Master ===\")\n",
    "print(master['DOC. TYPE'].value_counts().head(20))\n",
    "\n",
    "# Find all DEED-related document types from control codes\n",
    "deed_types = doc_codes[\n",
    "    doc_codes['CLASS CODE DESCRIPTION'] == 'DEEDS AND OTHER CONVEYANCES'\n",
    "]['DOC. TYPE'].unique()\n",
    "\n",
    "print(f\"\\n=== DEED Document Types (from control codes) ===\")\n",
    "print(deed_types)\n",
    "\n",
    "# Filter Master to only DEED transactions\n",
    "master_deeds = master[master['DOC. TYPE'].isin(deed_types)].copy()\n",
    "print(f\"\\nDeed transactions: {len(master_deeds):,}\")\n",
    "\n",
    "# Convert dates\n",
    "master_deeds['DOC. DATE'] = pd.to_datetime(master_deeds['DOC. DATE'], errors='coerce')\n",
    "master_deeds['RECORDED / FILED'] = pd.to_datetime(master_deeds['RECORDED / FILED'], errors='coerce')\n",
    "\n",
    "# Filter to 2015 onwards\n",
    "master_deeds = master_deeds[master_deeds['DOC. DATE'] >= '2015-01-01']\n",
    "print(f\"Deeds from 2015+: {len(master_deeds):,}\")\n",
    "\n",
    "# Clean document amount\n",
    "master_deeds['DOC. AMOUNT'] = pd.to_numeric(master_deeds['DOC. AMOUNT'], errors='coerce')\n",
    "\n",
    "# Filter out zero/low amounts (gifts, nominal transfers)\n",
    "master_deeds = master_deeds[master_deeds['DOC. AMOUNT'] > 1000]\n",
    "print(f\"After filtering low amounts: {len(master_deeds):,}\")\n",
    "\n",
    "# Keep essential columns\n",
    "master_clean = master_deeds[[\n",
    "    'DOCUMENT ID',      # To link to legals & parties\n",
    "    'BOROUGH',          # Borough code\n",
    "    'DOC. TYPE',        # Document type\n",
    "    'DOC. DATE',        # Transaction date\n",
    "    'DOC. AMOUNT',      # Sale price\n",
    "    'RECORDED / FILED', # Recording date\n",
    "    '% TRANSFERRED'     # Partial vs full transfer\n",
    "]].copy()\n",
    "\n",
    "# Create year column for analysis\n",
    "master_clean['sale_year'] = master_clean['DOC. DATE'].dt.year\n",
    "\n",
    "print(\"\\n=== Sales by Year ===\")\n",
    "print(master_clean['sale_year'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n=== Sales by Borough ===\")\n",
    "borough_map = {1: 'Manhattan', 2: 'Bronx', 3: 'Brooklyn', 4: 'Queens', 5: 'Staten Island'}\n",
    "master_clean['borough_name'] = master_clean['BOROUGH'].map(borough_map)\n",
    "print(master_clean['borough_name'].value_counts())\n",
    "\n",
    "# Save cleaned master\n",
    "master_clean.to_csv('acris_master_cleaned.csv', index=False)\n",
    "print(f\"\\n✓ Saved {len(master_clean):,} deed records to acris_master_cleaned.csv\")\n",
    "\n",
    "# Extract document IDs for filtering parties\n",
    "doc_ids = master_clean['DOCUMENT ID'].unique()\n",
    "print(f\"\\n✓ Found {len(doc_ids):,} unique document IDs\")\n",
    "\n",
    "# Save doc IDs for filtering parties\n",
    "pd.DataFrame({'document_id': doc_ids}).to_csv('document_ids_for_parties.csv', index=False)\n",
    "print(\"✓ Saved document IDs to document_ids_for_parties.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687629f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Loading ACRIS Legals...\n",
      "Original Legals records: 22,401,682\n",
      "Filtered Legals records: 453,001\n",
      "✓ Saved 414,018 legal records to acris_legals_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Clean ACRIS Legals\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Loading ACRIS Legals...\")\n",
    "legals = pd.read_csv('ACRIS_-_Real_Property_Legals_20251112.csv', low_memory=False)\n",
    "\n",
    "print(f\"Original Legals records: {len(legals):,}\")\n",
    "\n",
    "# Filter to only our document IDs\n",
    "legals_filtered = legals[legals['DOCUMENT ID'].isin(doc_ids)].copy()\n",
    "print(f\"Filtered Legals records: {len(legals_filtered):,}\")\n",
    "\n",
    "# Create BBL from Borough, Block, Lot\n",
    "legals_filtered['BBL'] = (\n",
    "    legals_filtered['BOROUGH'].astype(str).str.zfill(1) +\n",
    "    legals_filtered['BLOCK'].astype(str).str.zfill(5) +\n",
    "    legals_filtered['LOT'].astype(str).str.zfill(4)\n",
    ")\n",
    "\n",
    "# Keep essential columns\n",
    "legals_clean = legals_filtered[[\n",
    "    'DOCUMENT ID',\n",
    "    'BOROUGH',\n",
    "    'BLOCK',\n",
    "    'LOT',\n",
    "    'BBL',\n",
    "    'STREET NUMBER',\n",
    "    'STREET NAME',\n",
    "    'UNIT'\n",
    "]].copy()\n",
    "\n",
    "# Remove duplicates (some documents have multiple lots)\n",
    "# For now, keep first BBL per document\n",
    "legals_clean = legals_clean.drop_duplicates(subset=['DOCUMENT ID'], keep='first')\n",
    "\n",
    "legals_clean.to_csv('acris_legals_cleaned.csv', index=False)\n",
    "print(f\"✓ Saved {len(legals_clean):,} legal records to acris_legals_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3dc767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Loading ACRIS Parties...\n",
      "Original Parties records: 45,868,796\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'doc_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOriginal Parties records: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(parties)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Filter to only our document IDs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m parties_filtered = parties[parties[\u001b[33m'\u001b[39m\u001b[33mDOCUMENT ID\u001b[39m\u001b[33m'\u001b[39m].isin(\u001b[43mdoc_ids\u001b[49m)].copy()\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mParties for our documents: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(parties_filtered)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Check party types\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'doc_ids' is not defined"
     ]
    }
   ],
   "source": [
    "# Clean ACRIS Parties\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Loading ACRIS Parties...\")\n",
    "parties = pd.read_csv('ACRIS_-_Real_Property_Parties_20251112.csv', low_memory=False)\n",
    "\n",
    "print(f\"Original Parties records: {len(parties):,}\")\n",
    "\n",
    "# Filter to only our document IDs\n",
    "parties_filtered = parties[parties['DOCUMENT ID'].isin(doc_ids)].copy()\n",
    "print(f\"Parties for our documents: {len(parties_filtered):,}\")\n",
    "\n",
    "# Check party types\n",
    "print(\"\\n=== Party Types ===\")\n",
    "print(parties_filtered['PARTY TYPE'].value_counts())\n",
    "\n",
    "# Based on doc codes: PARTY2 = GRANTEE/BUYER for deeds\n",
    "# Filter to buyers only (adjust party type code if needed)\n",
    "buyers = parties_filtered[parties_filtered['PARTY TYPE'] == 2].copy()\n",
    "print(f\"\\nBuyers only: {len(buyers):,}\")\n",
    "\n",
    "# Clean names\n",
    "buyers['NAME'] = buyers['NAME'].str.strip().str.upper()\n",
    "\n",
    "# Identify institutional buyers\n",
    "institutional_keywords = [\n",
    "    'LLC', 'L.L.C', 'L L C',\n",
    "    'CORP', 'CORPORATION', \n",
    "    'INC', 'INCORPORATED',\n",
    "    'LTD', 'LIMITED',\n",
    "    'LP', 'L.P', 'LLP',\n",
    "    'TRUST',\n",
    "    'FUND',\n",
    "    'CAPITAL',\n",
    "    'HOLDINGS',\n",
    "    'PROPERTIES',\n",
    "    'REALTY',\n",
    "    'PARTNERS',\n",
    "    'VENTURES',\n",
    "    'INVESTMENTS',\n",
    "    'EQUITIES',\n",
    "    'GROUP',\n",
    "    'MANAGEMENT',\n",
    "    'ASSETS'\n",
    "]\n",
    "\n",
    "def is_institutional(name):\n",
    "    if pd.isna(name):\n",
    "        return False\n",
    "    name_upper = str(name).upper()\n",
    "    return any(keyword in name_upper for keyword in institutional_keywords)\n",
    "\n",
    "buyers['is_institutional'] = buyers['NAME'].apply(is_institutional)\n",
    "\n",
    "print(f\"\\n=== Buyer Analysis ===\")\n",
    "print(f\"Total buyers: {len(buyers):,}\")\n",
    "print(f\"Institutional buyers: {buyers['is_institutional'].sum():,} ({buyers['is_institutional'].mean()*100:.1f}%)\")\n",
    "print(f\"Individual buyers: {(~buyers['is_institutional']).sum():,}\")\n",
    "\n",
    "# Keep essential columns\n",
    "buyers_clean = buyers[[\n",
    "    'DOCUMENT ID',\n",
    "    'PARTY TYPE',\n",
    "    'NAME',\n",
    "    'is_institutional',\n",
    "    'ADDRESS 1',\n",
    "    'ADDRESS 2',\n",
    "    'CITY',\n",
    "    'STATE',\n",
    "    'ZIP',\n",
    "    'COUNTRY'\n",
    "]].copy()\n",
    "\n",
    "buyers_clean.to_csv('acris_buyers_cleaned.csv', index=False)\n",
    "print(f\"\\n✓ Saved {len(buyers_clean):,} buyer records to acris_buyers_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd23b42",
   "metadata": {},
   "source": [
    "##### Merge All Acris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105b304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Merging all ACRIS data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'master_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMerging all ACRIS data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Merge master + legals (to get BBL)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m acris = \u001b[43mmaster_clean\u001b[49m.merge(\n\u001b[32m      6\u001b[39m     legals_clean[[\u001b[33m'\u001b[39m\u001b[33mDOCUMENT ID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mBBL\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSTREET NUMBER\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSTREET NAME\u001b[39m\u001b[33m'\u001b[39m]],\n\u001b[32m      7\u001b[39m     on=\u001b[33m'\u001b[39m\u001b[33mDOCUMENT ID\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m     how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Merge with buyers (to get buyer info)\u001b[39;00m\n\u001b[32m     12\u001b[39m acris = acris.merge(\n\u001b[32m     13\u001b[39m     buyers_clean[[\u001b[33m'\u001b[39m\u001b[33mDOCUMENT ID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNAME\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mis_institutional\u001b[39m\u001b[33m'\u001b[39m]],\n\u001b[32m     14\u001b[39m     on=\u001b[33m'\u001b[39m\u001b[33mDOCUMENT ID\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     15\u001b[39m     how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'master_clean' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Merging all ACRIS data...\")\n",
    "\n",
    "# Merge master + legals (to get BBL)\n",
    "acris = master_clean.merge(\n",
    "    legals_clean[['DOCUMENT ID', 'BBL', 'STREET NUMBER', 'STREET NAME']],\n",
    "    on='DOCUMENT ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge with buyers (to get buyer info)\n",
    "acris = acris.merge(\n",
    "    buyers_clean[['DOCUMENT ID', 'NAME', 'is_institutional']],\n",
    "    on='DOCUMENT ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal merged dataset: {len(acris):,} records\")\n",
    "print(f\"Records with BBL: {acris['BBL'].notna().sum():,}\")\n",
    "print(f\"Records with buyer info: {acris['NAME'].notna().sum():,}\")\n",
    "\n",
    "# Rename columns for clarity\n",
    "acris = acris.rename(columns={\n",
    "    'DOC. DATE': 'sale_date',\n",
    "    'DOC. AMOUNT': 'sale_price',\n",
    "    'NAME': 'buyer_name'\n",
    "})\n",
    "\n",
    "acris.to_csv('acris_sales_final.csv', index=False)\n",
    "print(\"\\n✓ Saved final ACRIS sales data to acris_sales_final.csv\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n=== FINAL SUMMARY ===\")\n",
    "print(f\"Total property sales (2015+): {len(acris):,}\")\n",
    "print(f\"Institutional purchases: {acris['is_institutional'].sum():,}\")\n",
    "print(f\"Median sale price: ${acris['sale_price'].median():,.0f}\")\n",
    "print(f\"Properties with BBL: {acris['BBL'].notna().sum():,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
